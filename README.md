[![Grand Challenge](https://img.shields.io/badge/Grand%20Challenge-SynthRad_2025-blue)](https://synthrad2025.grand-challenge.org/) [![Hugging Face](https://img.shields.io/badge/ðŸ¤—%20Hugging%20Face-Synthrad_2025-orange)](https://huggingface.co/VBoussot/Synthrad2025)
# SynthRAD2025 â€“ Task 2 (ðŸ¥ˆ 3rd place)

This repository provides everything needed to build the Docker image and reproduce our solution ranked **3rd** in the **SynthRAD 2025 â€“ Task 2** challenge on synthetic CT generation from CBCT.

Our approach is based on a **2.5D U-Net++** with a ResNet-34 encoder, trained in two phases:
- Phase 1: joint pretraining on all anatomical regions (AB, TH, HN)
- Phase 2: fine-tuning separately on **AB-TH** and **HN**

The method was implemented using [KonfAI](https://github.com/vboussot/KonfAI), our modular deep learning framework. Training combines pixel-wise L1 loss with **perceptual losses** derived from **SAM** features.

Final predictions use **test-time augmentation** and **5-fold ensembling**, with a total of **10 models**:  
**5 trained for Abdomen/Thorax (AB-TH)** and **5 for Head & Neck (HN)**.  
Models were selected based on validation MAE.

ðŸ† **3rd place overall** 
(Related leaderboard: [SynthRAD Task 2 leaderboard](https://synthrad2025.grand-challenge.org/evaluation/test-task-1-cbct/leaderboard/))


| Rank | MAE â†“             | PSNR â†‘            | MS-SSIM â†‘        | DICE â†‘           | HD95 â†“           | Dose MAE photon â†“ | Dose MAE proton â†“ | DVH error photon â†“ | DVH error proton â†“ | GPR 2mm/2% photon â†‘ | GPR 2mm/2% proton â†‘ |
|------|-------------------|-------------------|------------------|------------------|------------------|-------------------|-------------------|---------------------|---------------------|----------------------|----------------------|
| 3    | 53.092 Â± 17.347 (3)| 32.490 Â± 2.292 (2)| 0.966 Â± 0.025 (2)| 0.843 Â± 0.079 (3)| 5.082 Â± 3.359 (4)| 0.005 Â± 0.004 (4) | 0.020 Â± 0.014 (4) | 0.015 Â± 0.019 (4)   | 0.036 Â± 0.019 (2)   | 99.308 Â± 1.102 (2)   | 86.407 Â± 8.415 (4)   |

---

## ðŸš€ Inference instructions

### 1. Install KonfAI

```bash
pip install konfai
```

---

### 2. Download pretrained weights

Download the pretrained models from Hugging Face:

ðŸ‘‰ https://huggingface.co/VBoussot/Synthrad2025

You should obtain:

```
Task_2/
â”œâ”€â”€ AB-TH/
â”‚   â”œâ”€â”€ CV_0.pt
â”‚   â”œâ”€â”€ CV_1.pt
â”‚   â”œâ”€â”€ CV_2.pt
â”‚   â”œâ”€â”€ CV_3.pt
â”‚   â”œâ”€â”€ CV_4.pt
â”‚   â””â”€â”€ Prediction.yml
â”‚
â””â”€â”€ HN/
    â”œâ”€â”€ CV_0.pt
    â”œâ”€â”€ CV_1.pt
    â”œâ”€â”€ CV_2.pt
    â”œâ”€â”€ CV_3.pt
    â”œâ”€â”€ CV_4.pt
    â””â”€â”€ Prediction.yml
```

---

### 3. Dataset structure

Your dataset should be structured as follows:

```
./Dataset/
â”œâ”€â”€ AB/
â”‚   â”œâ”€â”€ 2ABA002/
â”‚   â”‚   â”œâ”€â”€ CBCT.mha
â”‚   â”‚   â””â”€â”€ MASK.mha
â”‚   â”œâ”€â”€ 2ABA003/
â”‚   â”‚   â”œâ”€â”€ MR.mha
â”‚   â”‚   â””â”€â”€ MASK.mha
â”‚   â””â”€â”€ ...
â”œâ”€â”€ TH/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ HN/
â”‚   â”œâ”€â”€ 2HNA001/
â”‚   â”‚   â”œâ”€â”€ CBCT.mha
â”‚   â”‚   â””â”€â”€ MASK.mha
â”‚   â””â”€â”€ ...
```

### 3. Run inference (AB-TH example)

```bash
konfai PREDICTION -y --gpu 0 \
  --MODEL Task_2/AB-TH/CV_0.pt:Task_2/AB-TH/CV_1.pt:Task_2/AB-TH/CV_2.pt:Task_2/AB-TH/CV_3.pt:Task_2/AB-TH/CV_4.pt \
  --config Task_2/AB-TH/Prediction.yml
```

For **HN**, replace the path accordingly:

```bash
--MODEL Task_2/HN/CV_0.pt:Task_2/HN/CV_1.pt:Task_2/HN/CV_2.pt:Task_2/HN/CV_3.pt:Task_2/HN/CV_4.pt  --config Task_2/HN/Prediction.yml
```

---
## ðŸ› ï¸ How to Reproduce Training

Training is performed in **two phases**:

---

### ðŸ”¹ Phase 1 â€” Pretraining on all regions

Train a generic model on the full dataset (AB, TH, HN combined) (Fold 0 example):

```bash
konfai TRAIN -y --gpu 0 --config KonfAI/Plan/Phase_1/Config0.yml
```

---

### ðŸ”¹ Phase 2 â€” Region-specific fine-tuning

Fine-tune the Phase 1 model separately for each anatomical region.

#### Abdomen/Thorax (AB-TH) â€” Fold 0 example:

```bash
konfai RESUME -y --gpu 0 \
  --config KonfAI/Plan/Phase_2/AB-TH/Config0.yml \
  --MODEL Phase1.pt
```

#### Head & Neck (HN) â€” Fold 0 example:

```bash
konfai RESUME -y --gpu 0 \
  --config KonfAI/Plan/Phase_2/HN/Config0.yml \
  --MODEL Phase1.pt
```

> Replace `Phase1.pt` with the checkpoint from Phase 1 (best model from Fold 0).
